{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 9: The Map of Ideas\n",
    "\n",
    "## The Capital Archives — A Course in Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "*The archive is vast and disorganized. Manuscripts are shelved by acquisition date, not by subject. Finding all texts about a particular topic requires searching through thousands of documents.*\n",
    "\n",
    "*\"What if,\" the Chief asks, \"we could create a map? Not a physical map, but an intellectual one. A way to see how ideas cluster, how topics connect, how the archive's holdings relate to each other?\"*\n",
    "\n",
    "*This is the problem of **topic modeling**: discovering the hidden thematic structure in a collection of documents.*\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "- Topic modeling concepts\n",
    "- Latent Dirichlet Allocation (LDA)\n",
    "- Interpreting and visualizing topics\n",
    "- Using topics to understand document collections"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# COLAB SETUP - Run this cell first!\n# ============================================\n# This cell sets up the environment for Google Colab\n# Skip this cell if running locally\n\nimport os\n\n# Clone the repository if running in Colab\nif 'google.colab' in str(get_ipython()):\n    if not os.path.exists('capital-archives-nlp'):\n        !git clone https://github.com/buildLittleWorlds/capital-archives-nlp.git\n    os.chdir('capital-archives-nlp')\n    \n    # Install/download NLTK data\n    import nltk\n    nltk.download('punkt', quiet=True)\n    nltk.download('punkt_tab', quiet=True)\n    nltk.download('stopwords', quiet=True)\n    print(\"✓ Repository cloned and NLTK data downloaded!\")\nelse:\n    print(\"✓ Running locally - no setup needed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Topic modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "manuscripts = pd.read_csv('manuscripts.csv')\n",
    "texts = pd.read_csv('manuscript_texts.csv')\n",
    "\n",
    "corpus = texts.groupby('manuscript_id').agg(\n",
    "    text=('text', ' '.join)\n",
    ").reset_index()\n",
    "\n",
    "corpus = corpus.merge(\n",
    "    manuscripts[['manuscript_id', 'title', 'author', 'genre']],\n",
    "    on='manuscript_id', how='left'\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(corpus)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 What is Topic Modeling?\n",
    "\n",
    "**Topic modeling** is an unsupervised technique for discovering abstract \"topics\" in a collection of documents.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- A **topic** is a distribution over words (some words are more likely than others)\n",
    "- A **document** is a mixture of topics\n",
    "- The algorithm discovers both the topics AND how they're mixed in each document\n",
    "\n",
    "### LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "LDA assumes:\n",
    "1. There are K topics (you choose K)\n",
    "2. Each document is a mixture of these K topics\n",
    "3. Each word in a document comes from one of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Preparing Data for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document-term matrix using CountVectorizer\n",
    "# LDA works with raw counts, not TF-IDF\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=0.95,           # Ignore terms in >95% of documents\n",
    "    min_df=2,              # Ignore terms in <2 documents\n",
    "    max_features=1000,     # Keep top 1000 terms\n",
    "    stop_words='english',  # Remove stopwords\n",
    "    ngram_range=(1, 1)     # Unigrams only\n",
    ")\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(corpus['text'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Document-term matrix shape: {doc_term_matrix.shape}\")\n",
    "print(f\"  {doc_term_matrix.shape[0]} documents\")\n",
    "print(f\"  {doc_term_matrix.shape[1]} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Running LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of topics\n",
    "n_topics = 5  # Start small, adjust based on results\n",
    "\n",
    "# Fit LDA model\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=20,\n",
    "    learning_method='online'\n",
    ")\n",
    "\n",
    "doc_topics = lda.fit_transform(doc_term_matrix)\n",
    "\n",
    "print(f\"Fitted LDA with {n_topics} topics\")\n",
    "print(f\"Document-topic matrix shape: {doc_topics.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the topics\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    \"\"\"\n",
    "    Display the top words for each topic.\n",
    "    \"\"\"\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "        topics.append(top_words)\n",
    "        print(f\"\\nTopic {topic_idx}:\")\n",
    "        print(f\"  {', '.join(top_words)}\")\n",
    "    return topics\n",
    "\n",
    "topic_words = display_topics(lda, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Interpreting Topics\n",
    "\n",
    "Topics are just lists of words. We need to interpret what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to name the topics based on their top words\n",
    "# (This is subjective - you might interpret differently)\n",
    "\n",
    "# After looking at the words, assign labels\n",
    "# For now, use generic labels\n",
    "topic_labels = [f\"Topic {i}\" for i in range(n_topics)]\n",
    "\n",
    "# You can update these after inspecting the topics:\n",
    "# topic_labels = ['Philosophy of Language', 'Expeditions', 'Debates', 'Mirado/Water', 'Stone School']\n",
    "\n",
    "print(\"Topic labels (update based on your interpretation):\")\n",
    "for i, (label, words) in enumerate(zip(topic_labels, topic_words)):\n",
    "    print(f\"  {i}: {label} - {words[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 Document-Topic Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topic proportions to corpus\n",
    "for i in range(n_topics):\n",
    "    corpus[f'topic_{i}'] = doc_topics[:, i]\n",
    "\n",
    "# Find dominant topic for each document\n",
    "corpus['dominant_topic'] = doc_topics.argmax(axis=1)\n",
    "\n",
    "# Show example\n",
    "print(\"Topic distributions (first 10 documents):\")\n",
    "topic_cols = [f'topic_{i}' for i in range(n_topics)]\n",
    "print(corpus[['title', 'author', 'dominant_topic'] + topic_cols].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which documents are most representative of each topic?\n",
    "print(\"\\nMost representative documents per topic:\")\n",
    "for topic_id in range(n_topics):\n",
    "    top_docs = corpus.nlargest(3, f'topic_{topic_id}')\n",
    "    print(f\"\\nTopic {topic_id} ({topic_labels[topic_id]}):\")\n",
    "    for _, row in top_docs.iterrows():\n",
    "        print(f\"  {row['title'][:50]}... ({row[f'topic_{topic_id}']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Visualizing Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of documents across topics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Documents per dominant topic\n",
    "topic_counts = corpus['dominant_topic'].value_counts().sort_index()\n",
    "axes[0].bar(topic_counts.index, topic_counts.values, color='steelblue')\n",
    "axes[0].set_xlabel('Topic')\n",
    "axes[0].set_ylabel('Number of Documents')\n",
    "axes[0].set_title('Documents per Dominant Topic')\n",
    "axes[0].set_xticks(range(n_topics))\n",
    "\n",
    "# Average topic proportions\n",
    "avg_topics = corpus[topic_cols].mean()\n",
    "axes[1].bar(range(n_topics), avg_topics.values, color='steelblue')\n",
    "axes[1].set_xlabel('Topic')\n",
    "axes[1].set_ylabel('Average Proportion')\n",
    "axes[1].set_title('Average Topic Proportions Across All Documents')\n",
    "axes[1].set_xticks(range(n_topics))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic distribution by genre\n",
    "genre_topics = corpus.groupby('genre')[topic_cols].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "genre_topics.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_xlabel('Genre')\n",
    "ax.set_ylabel('Average Topic Proportion')\n",
    "ax.set_title('Topic Distribution by Genre')\n",
    "ax.legend(title='Topic', bbox_to_anchor=(1.02, 1))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic distribution by author\n",
    "author_counts = corpus['author'].value_counts()\n",
    "top_authors = author_counts[author_counts >= 2].index[:8]\n",
    "\n",
    "author_topics = corpus[corpus['author'].isin(top_authors)].groupby('author')[topic_cols].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "author_topics.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_xlabel('Author')\n",
    "ax.set_ylabel('Average Topic Proportion')\n",
    "ax.set_title('Topic Distribution by Author')\n",
    "ax.legend(title='Topic', bbox_to_anchor=(1.02, 1))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7 Finding Similar Documents by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate similarity based on topic distributions\n",
    "topic_similarity = cosine_similarity(doc_topics)\n",
    "\n",
    "def find_similar_by_topic(doc_idx, n=5):\n",
    "    \"\"\"\n",
    "    Find documents with similar topic distributions.\n",
    "    \"\"\"\n",
    "    similarities = topic_similarity[doc_idx]\n",
    "    similar_idx = similarities.argsort()[::-1][1:n+1]  # Exclude self\n",
    "    \n",
    "    results = []\n",
    "    for idx in similar_idx:\n",
    "        results.append({\n",
    "            'title': corpus.iloc[idx]['title'],\n",
    "            'author': corpus.iloc[idx]['author'],\n",
    "            'similarity': similarities[idx]\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example: find documents similar to first document\n",
    "print(f\"Documents similar to '{corpus.iloc[0]['title'][:40]}...':\")\n",
    "print(find_similar_by_topic(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.8 Choosing the Number of Topics\n",
    "\n",
    "How many topics should we use? This is often determined by:\n",
    "- Domain knowledge\n",
    "- Interpretability of resulting topics\n",
    "- Metrics like perplexity or coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different numbers of topics and compare perplexity\n",
    "topic_range = range(3, 10)\n",
    "perplexities = []\n",
    "\n",
    "for n in topic_range:\n",
    "    lda_temp = LatentDirichletAllocation(\n",
    "        n_components=n, random_state=42, max_iter=10, learning_method='online'\n",
    "    )\n",
    "    lda_temp.fit(doc_term_matrix)\n",
    "    perplexity = lda_temp.perplexity(doc_term_matrix)\n",
    "    perplexities.append(perplexity)\n",
    "    print(f\"  {n} topics: perplexity = {perplexity:.2f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(topic_range), perplexities, 'o-')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Perplexity (lower is better)')\n",
    "plt.title('LDA Perplexity vs. Number of Topics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.9 Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Topic modeling concepts**: Documents as mixtures of topics\n",
    "2. **LDA**: Latent Dirichlet Allocation for topic discovery\n",
    "3. **Topic interpretation**: Examining top words and representative documents\n",
    "4. **Visualization**: Topic distributions across documents, genres, authors\n",
    "5. **Model selection**: Choosing the number of topics\n",
    "\n",
    "### The Map Takes Shape\n",
    "\n",
    "Topic modeling reveals the intellectual geography of the archive:\n",
    "- What topics dominate the collection\n",
    "- How topics relate to genres and authors\n",
    "- Which documents share thematic concerns\n",
    "\n",
    "---\n",
    "\n",
    "*The Chief examines your topic map with interest. \"So the archive has structure after all,\" she says. \"Ideas cluster. Themes recur. Perhaps we can finally reorganize the shelves by topic rather than acquisition date.\" You suspect this reorganization will take years.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 9.1: Topic Labeling\n",
    "Examine the topic words carefully. Can you assign meaningful labels to each topic? What themes do they represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - update topic_labels based on your interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.2: NMF Comparison\n",
    "Try Non-negative Matrix Factorization (NMF) instead of LDA. How do the topics differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}