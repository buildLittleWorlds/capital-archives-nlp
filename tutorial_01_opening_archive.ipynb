{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Opening the Archive\n",
    "\n",
    "## The Capital Archives — A Course in Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "**Welcome, Junior Archivist.**\n",
    "\n",
    "You have been assigned to the archives district of the Capital, that labyrinthine network of licensed shops near the Senate-house. Each shop has its single round window—no walk-in entrance—where archivists dispense manuscripts, maps, expedition reports, and philosophical treatises to those who know what to ask for.\n",
    "\n",
    "The Chief Archivist has handed you a catalog and a simple task: take inventory. Before you can do anything sophisticated with these texts, you need to understand what you have.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "- How to load and inspect tabular data with pandas\n",
    "- How to load and inspect text data\n",
    "- Basic string operations and counting\n",
    "- How to explore a corpus before analyzing it\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# COLAB SETUP - Run this cell first!\n# ============================================\n# This cell sets up the environment for Google Colab\n# Skip this cell if running locally\n\nimport os\n\n# Clone the repository if running in Colab\nif 'google.colab' in str(get_ipython()):\n    if not os.path.exists('capital-archives-nlp'):\n        !git clone https://github.com/buildLittleWorlds/capital-archives-nlp.git\n    os.chdir('capital-archives-nlp')\n    print(\"✓ Repository cloned and ready!\")\nelse:\n    print(\"✓ Running locally - no setup needed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Setting Up Your Workspace\n",
    "\n",
    "Every archivist needs tools. We'll start by importing the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For displaying data nicely\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Verify everything is loaded\n",
    "print(\"Workspace ready. Tools loaded.\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading the Manuscript Catalog\n",
    "\n",
    "The Chief has given you access to the central catalog—a record of every manuscript in the district's collections. Let's load it and see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the manuscript catalog\n",
    "manuscripts = pd.read_csv('data/manuscripts.csv')\n",
    "\n",
    "# How many manuscripts do we have?\n",
    "print(f\"Total manuscripts in the catalog: {len(manuscripts)}\")\n",
    "\n",
    "# What information do we have about each one?\n",
    "print(f\"\\nColumns in the catalog:\")\n",
    "for col in manuscripts.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the first few entries\n",
    "manuscripts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Catalog\n",
    "\n",
    "Each row represents a manuscript in the archives. The columns tell us:\n",
    "- **manuscript_id**: Unique identifier (MS-0001, MS-0002, etc.)\n",
    "- **title**: The name of the work\n",
    "- **author**: Who wrote it (sometimes \"Anonymous\" or \"attributed to...\")\n",
    "- **genre**: What kind of text it is (treatise, debate transcript, expedition report, etc.)\n",
    "- **condition**: Physical state of the manuscript\n",
    "- **authenticity_status**: Whether scholars believe it's genuine\n",
    "\n",
    "Let's explore each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Counting and Grouping: What Do We Have?\n",
    "\n",
    "The first task of any archivist is inventory. Let's count what kinds of manuscripts we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count manuscripts by genre\n",
    "genre_counts = manuscripts['genre'].value_counts()\n",
    "\n",
    "print(\"Manuscripts by genre:\")\n",
    "print(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "genre_counts.plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Number of Manuscripts')\n",
    "ax.set_ylabel('Genre')\n",
    "ax.set_title('Archive Holdings by Genre')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Explore Other Categories\n",
    "\n",
    "The genre distribution tells us what kinds of texts dominate the collection. But there are other ways to slice the data. Try counting manuscripts by:\n",
    "1. Condition (how many are damaged?)\n",
    "2. Authenticity status (how many are disputed?)\n",
    "3. Author (who wrote the most?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Count manuscripts by condition\n",
    "condition_counts = manuscripts['condition'].value_counts()\n",
    "print(\"Manuscripts by condition:\")\n",
    "print(condition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Count manuscripts by authenticity_status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Who are the most prolific authors?\n",
    "# Hint: Use value_counts() and maybe .head(10) to see the top authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Loading the Actual Texts\n",
    "\n",
    "The catalog tells us *about* manuscripts, but to do text analysis, we need the texts themselves. The archive has transcribed many of the most important works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transcribed texts\n",
    "texts = pd.read_csv('data/manuscript_texts.csv')\n",
    "\n",
    "print(f\"Total text sections: {len(texts)}\")\n",
    "print(f\"Columns: {list(texts.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each manuscript may have multiple sections\n",
    "# Let's see how many unique manuscripts have been transcribed\n",
    "unique_manuscripts = texts['manuscript_id'].nunique()\n",
    "print(f\"Unique manuscripts with text: {unique_manuscripts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one example text\n",
    "sample = texts[texts['manuscript_id'] == 'MS-0012'].iloc[0]\n",
    "print(f\"Manuscript: {sample['manuscript_id']}\")\n",
    "print(f\"Section: {sample['section']}\")\n",
    "print(f\"\\nText (first 500 characters):\")\n",
    "print(sample['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Basic Text Statistics\n",
    "\n",
    "Before sophisticated analysis, we need basic statistics about our texts. How long are they? How many words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word counts for each section\n",
    "# A simple approach: split on whitespace and count\n",
    "texts['word_count'] = texts['text'].str.split().str.len()\n",
    "\n",
    "print(\"Word count statistics (per section):\")\n",
    "print(texts['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's aggregate by manuscript (some have multiple sections)\n",
    "manuscript_stats = texts.groupby('manuscript_id').agg(\n",
    "    total_words=('word_count', 'sum'),\n",
    "    num_sections=('section', 'count'),\n",
    "    full_text=('text', ' '.join)  # Combine all sections\n",
    ").reset_index()\n",
    "\n",
    "print(f\"\\nManuscripts with text: {len(manuscript_stats)}\")\n",
    "print(f\"Total words in collection: {manuscript_stats['total_words'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which manuscripts are the longest?\n",
    "print(\"Longest manuscripts:\")\n",
    "print(manuscript_stats.nlargest(10, 'total_words')[['manuscript_id', 'total_words', 'num_sections']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are the shortest?\n",
    "print(\"Shortest manuscripts:\")\n",
    "print(manuscript_stats.nsmallest(10, 'total_words')[['manuscript_id', 'total_words', 'num_sections']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Joining Data: Connecting Texts to Metadata\n",
    "\n",
    "The real power comes when we connect our texts to their metadata. Who wrote the longest works? Which genres have the most words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the manuscript stats with the catalog\n",
    "# This gives us metadata for each text we have\n",
    "texts_with_metadata = manuscript_stats.merge(\n",
    "    manuscripts[['manuscript_id', 'title', 'author', 'genre', 'condition', 'authenticity_status']],\n",
    "    on='manuscript_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "texts_with_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can ask: which authors wrote the most words in our transcribed collection?\n",
    "author_words = texts_with_metadata.groupby('author')['total_words'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Words by author (transcribed texts only):\")\n",
    "print(author_words.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average manuscript length by genre\n",
    "genre_length = texts_with_metadata.groupby('genre')['total_words'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Average manuscript length by genre:\")\n",
    "print(genre_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Your First Text Exploration\n",
    "\n",
    "Let's pick a single manuscript and explore it in detail. This is the kind of close reading you'll do throughout the course—getting to know individual texts before applying computational methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a manuscript to explore\n",
    "# Let's look at one of the philosophical treatises\n",
    "target_id = 'MS-0012'  # This is Grigsu's \"On the Permanence of the Uttered\"\n",
    "\n",
    "# Get metadata\n",
    "meta = manuscripts[manuscripts['manuscript_id'] == target_id].iloc[0]\n",
    "print(f\"Title: {meta['title']}\")\n",
    "print(f\"Author: {meta['author']}\")\n",
    "print(f\"Genre: {meta['genre']}\")\n",
    "print(f\"Condition: {meta['condition']}\")\n",
    "print(f\"Authenticity: {meta['authenticity_status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full text\n",
    "target_text = ' '.join(texts[texts['manuscript_id'] == target_id]['text'].tolist())\n",
    "\n",
    "# Basic stats\n",
    "words = target_text.split()\n",
    "print(f\"\\nWord count: {len(words)}\")\n",
    "print(f\"Character count: {len(target_text)}\")\n",
    "print(f\"Average word length: {sum(len(w) for w in words) / len(words):.1f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most common words?\n",
    "from collections import Counter\n",
    "\n",
    "# Simple word frequency (we'll do this more sophisticatedly later)\n",
    "word_freq = Counter(word.lower() for word in words)\n",
    "\n",
    "print(\"Most common words:\")\n",
    "for word, count in word_freq.most_common(20):\n",
    "    print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the most common words are mostly \"function words\" like *the*, *is*, *a*, *to*. These are common in all English text. In later tutorials, we'll learn to filter these out to find the \"content words\" that distinguish one text from another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Exercise: Explore Another Manuscript\n",
    "\n",
    "Choose a different manuscript and perform the same exploration. Pick something that interests you—maybe a debate transcript, an expedition report, or a text by a different author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's see what manuscripts have text available\n",
    "available = texts_with_metadata[['manuscript_id', 'title', 'author', 'genre', 'total_words']]\n",
    "print(available.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Choose a manuscript_id and explore it\n",
    "my_target_id = 'MS-0008'  # Change this to your chosen manuscript\n",
    "\n",
    "# Get metadata\n",
    "my_meta = manuscripts[manuscripts['manuscript_id'] == my_target_id].iloc[0]\n",
    "print(f\"Title: {my_meta['title']}\")\n",
    "print(f\"Author: {my_meta['author']}\")\n",
    "\n",
    "# Get text and calculate stats\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Loading Other Archive Data\n",
    "\n",
    "The archive contains more than just manuscripts. Let's load the other data files we'll use throughout this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the archive data\n",
    "scholars = pd.read_csv('data/scholars.csv')\n",
    "debates = pd.read_csv('data/debates.csv')\n",
    "shops = pd.read_csv('data/archivist_shops.csv')\n",
    "expeditions = pd.read_csv('data/expeditions.csv')\n",
    "word_index = pd.read_csv('data/word_index.csv')\n",
    "\n",
    "print(\"Archive data loaded:\")\n",
    "print(f\"  Scholars: {len(scholars)} records\")\n",
    "print(f\"  Debates: {len(debates)} records\")\n",
    "print(f\"  Archive Shops: {len(shops)} records\")\n",
    "print(f\"  Expeditions: {len(expeditions)} records\")\n",
    "print(f\"  Word Index: {len(word_index)} terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the scholars\n",
    "print(\"Scholars by philosophical school:\")\n",
    "print(scholars['philosophical_school'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The word index is particularly interesting for NLP\n",
    "# It shows how different schools define the same terms\n",
    "word_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Summary and Next Steps\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Loading data with pandas**: `pd.read_csv()` to load tabular data\n",
    "2. **Basic exploration**: `.head()`, `.info()`, `.describe()`, `.value_counts()`\n",
    "3. **Counting and grouping**: Finding patterns in categorical data\n",
    "4. **Text statistics**: Word counts, character counts, basic frequency\n",
    "5. **Joining data**: Connecting texts to their metadata with `.merge()`\n",
    "\n",
    "### The Archive Awaits\n",
    "\n",
    "You now have a basic map of the archive's holdings. You know:\n",
    "- What kinds of documents we have\n",
    "- Who wrote them\n",
    "- How long they are\n",
    "- Which ones have been transcribed\n",
    "\n",
    "In the next tutorial, we'll dig into **cleaning and standardizing** the texts. Many of these manuscripts have inconsistencies, errors, and quirks that need to be addressed before serious analysis can begin.\n",
    "\n",
    "---\n",
    "\n",
    "*The Chief Archivist nods approvingly at your inventory report. \"Good,\" she says. \"Now you know what we have. Tomorrow, we'll teach you to make sense of it.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Before moving on, complete these exercises to solidify your understanding:\n",
    "\n",
    "### Exercise 1.2: Suspicious Manuscripts\n",
    "Find all manuscripts with `authenticity_status` of \"suspected_forgery\". What do they have in common? Who are they attributed to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: The Scholars\n",
    "Using the `scholars.csv` file, find all scholars belonging to the \"stone_school\". What are their names? What manuscripts did they write? (Hint: the `major_works` column contains manuscript IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4: Word Count Distribution\n",
    "Create a histogram showing the distribution of manuscript lengths (total_words). Are most manuscripts short or long? Are there outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}