{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Sorting the Schools\n",
    "\n",
    "## The Capital Archives — A Course in Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "*Many manuscripts in the archive are anonymous or have disputed attributions. \"Who wrote this?\" is often less certain than we'd like. But perhaps the text itself contains clues. Perhaps documents from the same philosophical school share something—a vocabulary, a style, an emphasis—that allows us to group them together.*\n",
    "\n",
    "*The Chief Archivist suspects some 'anonymous' manuscripts can be sorted into schools by style alone.*\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "- TF-IDF: Term Frequency-Inverse Document Frequency\n",
    "- Document similarity with cosine similarity\n",
    "- Document clustering\n",
    "- Visualizing document relationships"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# COLAB SETUP - Run this cell first!\n# ============================================\n# This cell sets up the environment for Google Colab\n# Skip this cell if running locally\n\nimport os\n\n# Clone the repository if running in Colab\nif 'google.colab' in str(get_ipython()):\n    if not os.path.exists('capital-archives-nlp'):\n        !git clone https://github.com/buildLittleWorlds/capital-archives-nlp.git\n    os.chdir('capital-archives-nlp')\n    print(\"✓ Repository cloned and ready!\")\nelse:\n    print(\"✓ Running locally - no setup needed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "manuscripts = pd.read_csv('data/manuscripts.csv')\n",
    "texts = pd.read_csv('data/manuscript_texts.csv')\n",
    "scholars = pd.read_csv('data/scholars.csv')\n",
    "\n",
    "corpus = texts.groupby('manuscript_id').agg(\n",
    "    text=('text', ' '.join)\n",
    ").reset_index()\n",
    "\n",
    "corpus = corpus.merge(\n",
    "    manuscripts[['manuscript_id', 'title', 'author', 'genre', 'authenticity_status']],\n",
    "    on='manuscript_id', how='left'\n",
    ")\n",
    "\n",
    "# Get philosophical school for each author\n",
    "author_school = dict(zip(scholars['name'], scholars['philosophical_school']))\n",
    "corpus['school'] = corpus['author'].map(author_school).fillna('unknown')\n",
    "\n",
    "print(f\"Loaded {len(corpus)} documents\")\n",
    "print(f\"\\nDocuments by school:\")\n",
    "print(corpus['school'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 From Counts to TF-IDF\n",
    "\n",
    "Raw word counts are problematic: long documents have more of everything. And common words dominate.\n",
    "\n",
    "**TF-IDF** addresses both problems:\n",
    "- **TF (Term Frequency)**: How often does this word appear in this document?\n",
    "- **IDF (Inverse Document Frequency)**: How rare is this word across all documents?\n",
    "\n",
    "TF-IDF = TF × IDF\n",
    "\n",
    "Words that appear frequently in one document but rarely elsewhere get high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,      # Use top 1000 terms\n",
    "    min_df=2,               # Ignore terms in fewer than 2 documents\n",
    "    max_df=0.95,            # Ignore terms in more than 95% of documents\n",
    "    stop_words='english',   # Remove English stopwords\n",
    "    ngram_range=(1, 2)      # Include unigrams and bigrams\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(corpus['text'])\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"  {tfidf_matrix.shape[0]} documents\")\n",
    "print(f\"  {tfidf_matrix.shape[1]} features (terms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names (terms)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"Sample terms in vocabulary:\")\n",
    "print(feature_names[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What terms have the highest TF-IDF scores for a specific document?\n",
    "def get_top_tfidf_terms(doc_index, n=15):\n",
    "    \"\"\"\n",
    "    Get the top TF-IDF terms for a document.\n",
    "    \"\"\"\n",
    "    doc_vector = tfidf_matrix[doc_index].toarray().flatten()\n",
    "    top_indices = doc_vector.argsort()[-n:][::-1]\n",
    "    \n",
    "    return [(feature_names[i], doc_vector[i]) for i in top_indices]\n",
    "\n",
    "# Example: top terms for first document\n",
    "doc_idx = 0\n",
    "print(f\"Top TF-IDF terms for '{corpus.iloc[doc_idx]['title'][:50]}...'\")\n",
    "print(f\"Author: {corpus.iloc[doc_idx]['author']}\")\n",
    "print()\n",
    "for term, score in get_top_tfidf_terms(doc_idx):\n",
    "    print(f\"  {term}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Document Similarity\n",
    "\n",
    "With TF-IDF vectors, we can measure how similar documents are using **cosine similarity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise similarities\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_documents(doc_index, n=5):\n",
    "    \"\"\"\n",
    "    Find documents most similar to a given document.\n",
    "    \"\"\"\n",
    "    similarities = similarity_matrix[doc_index]\n",
    "    # Get indices sorted by similarity (excluding self)\n",
    "    similar_indices = similarities.argsort()[::-1][1:n+1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in similar_indices:\n",
    "        results.append({\n",
    "            'title': corpus.iloc[idx]['title'],\n",
    "            'author': corpus.iloc[idx]['author'],\n",
    "            'similarity': similarities[idx]\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Find documents similar to a Grigsu text\n",
    "grigsu_docs = corpus[corpus['author'] == 'Grigsu Haldo']\n",
    "if len(grigsu_docs) > 0:\n",
    "    doc_idx = grigsu_docs.index[0]\n",
    "    print(f\"Documents similar to '{corpus.iloc[doc_idx]['title'][:50]}...'\")\n",
    "    print(f\"by {corpus.iloc[doc_idx]['author']}\\n\")\n",
    "    print(find_similar_documents(doc_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Clustering Documents\n",
    "\n",
    "Can we automatically group documents into clusters based on their TF-IDF vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster documents using K-means\n",
    "n_clusters = 4  # Let's try 4 clusters\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "corpus['cluster'] = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "print(\"Documents per cluster:\")\n",
    "print(corpus['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What characterizes each cluster?\n",
    "def get_cluster_terms(cluster_id, n=10):\n",
    "    \"\"\"\n",
    "    Get the most distinctive terms for a cluster.\n",
    "    \"\"\"\n",
    "    cluster_docs = corpus[corpus['cluster'] == cluster_id].index\n",
    "    cluster_vectors = tfidf_matrix[cluster_docs].toarray()\n",
    "    mean_vector = cluster_vectors.mean(axis=0)\n",
    "    \n",
    "    top_indices = mean_vector.argsort()[-n:][::-1]\n",
    "    return [(feature_names[i], mean_vector[i]) for i in top_indices]\n",
    "\n",
    "# Show top terms for each cluster\n",
    "for cluster_id in range(n_clusters):\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    for term, score in get_cluster_terms(cluster_id):\n",
    "        print(f\"  {term}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do clusters align with philosophical schools?\n",
    "cluster_school = pd.crosstab(corpus['cluster'], corpus['school'])\n",
    "print(\"Clusters vs Philosophical Schools:\")\n",
    "print(cluster_school)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Visualizing Document Space\n",
    "\n",
    "We can't visualize 1000-dimensional TF-IDF space directly, but we can reduce it to 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D using PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "coords_pca = pca.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "corpus['pca_x'] = coords_pca[:, 0]\n",
    "corpus['pca_y'] = coords_pca[:, 1]\n",
    "\n",
    "print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot documents colored by school\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "schools = corpus['school'].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(schools)))\n",
    "\n",
    "for school, color in zip(schools, colors):\n",
    "    mask = corpus['school'] == school\n",
    "    ax.scatter(corpus.loc[mask, 'pca_x'], \n",
    "               corpus.loc[mask, 'pca_y'],\n",
    "               label=school, alpha=0.7, s=100, c=[color])\n",
    "\n",
    "ax.set_xlabel('PCA Component 1')\n",
    "ax.set_ylabel('PCA Component 2')\n",
    "ax.set_title('Documents in TF-IDF Space (PCA)')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try t-SNE for potentially better separation\n",
    "# t-SNE is better at preserving local structure\n",
    "if len(corpus) > 10:  # t-SNE needs enough points\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(corpus)-1))\n",
    "    coords_tsne = tsne.fit_transform(tfidf_matrix.toarray())\n",
    "    \n",
    "    corpus['tsne_x'] = coords_tsne[:, 0]\n",
    "    corpus['tsne_y'] = coords_tsne[:, 1]\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    for school, color in zip(schools, colors):\n",
    "        mask = corpus['school'] == school\n",
    "        ax.scatter(corpus.loc[mask, 'tsne_x'], \n",
    "                   corpus.loc[mask, 'tsne_y'],\n",
    "                   label=school, alpha=0.7, s=100, c=[color])\n",
    "    \n",
    "    ax.set_xlabel('t-SNE 1')\n",
    "    ax.set_ylabel('t-SNE 2')\n",
    "    ax.set_title('Documents in TF-IDF Space (t-SNE)')\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Investigating Suspicious Documents\n",
    "\n",
    "Let's look at documents with suspected forgery status. Where do they cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find suspected forgeries\n",
    "suspicious = corpus[corpus['authenticity_status'] == 'suspected_forgery']\n",
    "\n",
    "print(f\"Suspected forgeries in corpus: {len(suspicious)}\")\n",
    "if len(suspicious) > 0:\n",
    "    print(suspicious[['manuscript_id', 'title', 'author', 'cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have suspected forgeries attributed to Grigsu, \n",
    "# do they cluster with authentic Grigsu or with other schools?\n",
    "\n",
    "if len(suspicious) > 0:\n",
    "    # Check what cluster the suspicious docs are in\n",
    "    print(\"\\nSuspicious documents by cluster:\")\n",
    "    print(suspicious[['title', 'author', 'cluster']])\n",
    "    \n",
    "    # Compare to authentic documents by same attributed author\n",
    "    for _, sus_doc in suspicious.iterrows():\n",
    "        claimed_author = sus_doc['author']\n",
    "        print(f\"\\n{sus_doc['title'][:50]}...\")\n",
    "        print(f\"  Attributed to: {claimed_author}\")\n",
    "        print(f\"  Cluster: {sus_doc['cluster']}\")\n",
    "        \n",
    "        # Find most similar documents\n",
    "        doc_idx = corpus[corpus['manuscript_id'] == sus_doc['manuscript_id']].index[0]\n",
    "        similar = find_similar_documents(doc_idx, n=3)\n",
    "        print(f\"  Most similar to:\")\n",
    "        for _, row in similar.iterrows():\n",
    "            print(f\"    - {row['title'][:40]}... by {row['author']} (sim={row['similarity']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **TF-IDF**: Representing documents as weighted term vectors\n",
    "2. **Cosine similarity**: Measuring document similarity\n",
    "3. **K-means clustering**: Grouping documents automatically\n",
    "4. **Dimensionality reduction**: PCA and t-SNE for visualization\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- Documents can be represented as vectors in term space\n",
    "- Similar documents cluster together based on vocabulary\n",
    "- Clusters may align with philosophical schools, genres, or authors\n",
    "- Suspected forgeries may cluster with unexpected groups\n",
    "\n",
    "---\n",
    "\n",
    "*The visualization reveals patterns invisible to the naked eye. Documents cluster by philosophical affinity, and some 'anonymous' texts now reveal their likely origins. But what of the suspected forgeries? If they cluster with the wrong school, that would be evidence of inauthenticity...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 6.1: Optimal Clusters\n",
    "Try different values of k for K-means clustering. Use the elbow method or silhouette score to find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Try k from 2 to 8\n",
    "# Calculate inertia and silhouette score for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2: Genre Clustering\n",
    "Do documents cluster better by genre than by philosophical school? Create a visualization colored by genre and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3: Document Similarity Search\n",
    "Build a simple search function: given a query text (not in the corpus), find the most similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def search_similar(query_text, top_n=5):\n",
    "    \"\"\"\n",
    "    Find documents most similar to a query.\n",
    "    \"\"\"\n",
    "    # Transform query using the fitted TF-IDF vectorizer\n",
    "    query_vector = tfidf.transform([query_text])\n",
    "    \n",
    "    # Calculate similarity to all documents\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}