{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8: Sentiment in the Margins\n",
    "\n",
    "## The Capital Archives — A Course in Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "*The margins of manuscripts tell their own stories. Readers leave notes: \"Brilliant!\" \"This is wrong.\" \"See also MS-0034.\" \"The author contradicts himself.\" These annotations reveal what readers thought of these texts—a reception history written in hasty ink.*\n",
    "\n",
    "*The Chief wants to understand how different scholars and texts were received. What did readers think of Grigsu? Of Yasho? Did opinions change over time?*\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "- Sentiment analysis basics\n",
    "- Using VADER for sentiment scoring\n",
    "- Analyzing opinion and emotion in text\n",
    "- Tracking sentiment across documents and time"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# COLAB SETUP - Run this cell first!\n# ============================================\n# This cell sets up the environment for Google Colab\n# Skip this cell if running locally\n\nimport os\n\n# Clone the repository if running in Colab\nif 'google.colab' in str(get_ipython()):\n    if not os.path.exists('capital-archives-nlp'):\n        !git clone https://github.com/buildLittleWorlds/capital-archives-nlp.git\n    os.chdir('capital-archives-nlp')\n    \n    # Install/download NLTK data\n    import nltk\n    nltk.download('punkt', quiet=True)\n    nltk.download('punkt_tab', quiet=True)\n    nltk.download('vader_lexicon', quiet=True)\n    print(\"✓ Repository cloned and NLTK data downloaded!\")\nelse:\n    print(\"✓ Running locally - no setup needed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "manuscripts = pd.read_csv('manuscripts.csv')\n",
    "texts = pd.read_csv('manuscript_texts.csv')\n",
    "\n",
    "corpus = texts.groupby('manuscript_id').agg(\n",
    "    text=('text', ' '.join)\n",
    ").reset_index()\n",
    "\n",
    "corpus = corpus.merge(\n",
    "    manuscripts[['manuscript_id', 'title', 'author', 'genre']],\n",
    "    on='manuscript_id', how='left'\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(corpus)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 What is Sentiment Analysis?\n",
    "\n",
    "**Sentiment analysis** determines the emotional tone of text:\n",
    "- **Positive**: Happy, good, excellent, wonderful\n",
    "- **Negative**: Bad, terrible, wrong, hate\n",
    "- **Neutral**: Factual, objective, neither positive nor negative\n",
    "\n",
    "### VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "\n",
    "VADER is a rule-based sentiment analyzer specifically tuned for social media but works well for general text. It provides:\n",
    "- **neg**: Negative sentiment (0-1)\n",
    "- **neu**: Neutral sentiment (0-1)\n",
    "- **pos**: Positive sentiment (0-1)\n",
    "- **compound**: Overall sentiment (-1 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test on some sample sentences\n",
    "test_sentences = [\n",
    "    \"Grigsu's argument is brilliant and convincing.\",\n",
    "    \"This theory is completely wrong and foolish.\",\n",
    "    \"The expedition departed on the third day of the month.\",\n",
    "    \"The stone-school has been thoroughly discredited!\",\n",
    "    \"A nuanced and thoughtful analysis of word theory.\"\n",
    "]\n",
    "\n",
    "print(\"Sentiment analysis examples:\")\n",
    "for sentence in test_sentences:\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    print(f\"\\n'{sentence}'\")\n",
    "    print(f\"  Positive: {scores['pos']:.3f}\")\n",
    "    print(f\"  Negative: {scores['neg']:.3f}\")\n",
    "    print(f\"  Neutral: {scores['neu']:.3f}\")\n",
    "    print(f\"  Compound: {scores['compound']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Analyzing Document Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of a text.\n",
    "    \n",
    "    Returns dict with overall scores and sentence-level analysis.\n",
    "    \"\"\"\n",
    "    # Overall document sentiment\n",
    "    overall = sia.polarity_scores(text)\n",
    "    \n",
    "    # Sentence-level sentiment\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_scores = [sia.polarity_scores(s)['compound'] for s in sentences]\n",
    "    \n",
    "    return {\n",
    "        'compound': overall['compound'],\n",
    "        'positive': overall['pos'],\n",
    "        'negative': overall['neg'],\n",
    "        'neutral': overall['neu'],\n",
    "        'num_sentences': len(sentences),\n",
    "        'avg_sentence_sentiment': np.mean(sentence_scores) if sentence_scores else 0,\n",
    "        'std_sentence_sentiment': np.std(sentence_scores) if sentence_scores else 0,\n",
    "        'positive_sentences': sum(1 for s in sentence_scores if s > 0.05),\n",
    "        'negative_sentences': sum(1 for s in sentence_scores if s < -0.05),\n",
    "        'neutral_sentences': sum(1 for s in sentence_scores if -0.05 <= s <= 0.05)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment for all documents\n",
    "sentiment_data = []\n",
    "for _, row in corpus.iterrows():\n",
    "    sent = analyze_sentiment(row['text'])\n",
    "    sent['manuscript_id'] = row['manuscript_id']\n",
    "    sent['author'] = row['author']\n",
    "    sent['genre'] = row['genre']\n",
    "    sent['title'] = row['title']\n",
    "    sentiment_data.append(sent)\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiment_data)\n",
    "print(f\"Analyzed {len(sentiment_df)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary\n",
    "print(\"\\nSentiment summary:\")\n",
    "print(sentiment_df[['compound', 'positive', 'negative', 'neutral']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most positive and most negative documents\n",
    "print(\"\\nMost positive documents:\")\n",
    "print(sentiment_df.nlargest(5, 'compound')[['title', 'author', 'compound']])\n",
    "\n",
    "print(\"\\nMost negative documents:\")\n",
    "print(sentiment_df.nsmallest(5, 'compound')[['title', 'author', 'compound']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Sentiment by Author and Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentiment by author\n",
    "author_sentiment = sentiment_df.groupby('author').agg({\n",
    "    'compound': 'mean',\n",
    "    'positive': 'mean',\n",
    "    'negative': 'mean',\n",
    "    'manuscript_id': 'count'\n",
    "}).rename(columns={'manuscript_id': 'num_docs'}).round(3)\n",
    "\n",
    "print(\"Sentiment by author (sorted by compound):\")\n",
    "print(author_sentiment.sort_values('compound', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentiment by genre\n",
    "genre_sentiment = sentiment_df.groupby('genre').agg({\n",
    "    'compound': 'mean',\n",
    "    'positive': 'mean',\n",
    "    'negative': 'mean',\n",
    "    'std_sentence_sentiment': 'mean',\n",
    "    'manuscript_id': 'count'\n",
    "}).rename(columns={'manuscript_id': 'num_docs'}).round(3)\n",
    "\n",
    "print(\"\\nSentiment by genre:\")\n",
    "print(genre_sentiment.sort_values('compound', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Genre sentiment\n",
    "genre_sentiment.sort_values('compound')['compound'].plot(\n",
    "    kind='barh', ax=axes[0], color='steelblue'\n",
    ")\n",
    "axes[0].axvline(x=0, color='gray', linestyle='--')\n",
    "axes[0].set_xlabel('Compound Sentiment')\n",
    "axes[0].set_title('Sentiment by Genre')\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_df['compound'].hist(bins=20, ax=axes[1], color='steelblue', edgecolor='white')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', label='Neutral')\n",
    "axes[1].set_xlabel('Compound Sentiment')\n",
    "axes[1].set_ylabel('Number of Documents')\n",
    "axes[1].set_title('Distribution of Document Sentiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Analyzing Debates\n",
    "\n",
    "Debates should show interesting sentiment patterns—arguments for and against, emotional exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on debate transcripts\n",
    "debates = sentiment_df[sentiment_df['genre'] == 'debate_transcript']\n",
    "\n",
    "print(f\"Debate transcripts: {len(debates)}\")\n",
    "if len(debates) > 0:\n",
    "    print(\"\\nDebates by sentiment:\")\n",
    "    print(debates[['title', 'compound', 'positive_sentences', 'negative_sentences']].sort_values('compound'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment variation within debates\n",
    "if len(debates) > 0:\n",
    "    print(\"\\nSentiment variability in debates:\")\n",
    "    print(debates[['title', 'std_sentence_sentiment']].sort_values('std_sentence_sentiment', ascending=False).head())\n",
    "    \n",
    "    # High variability = contentious debate with swings between positive and negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Sentiment About Specific Entities\n",
    "\n",
    "What do texts say about specific scholars or concepts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_around_entity(text, entity, window=50):\n",
    "    \"\"\"\n",
    "    Analyze sentiment in text windows around mentions of an entity.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The document text\n",
    "    entity : str\n",
    "        The entity to search for (case-insensitive)\n",
    "    window : int\n",
    "        Characters before and after to include\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of (context, sentiment) tuples\n",
    "    \"\"\"\n",
    "    entity_lower = entity.lower()\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    results = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        pos = text_lower.find(entity_lower, start)\n",
    "        if pos == -1:\n",
    "            break\n",
    "        \n",
    "        # Extract context window\n",
    "        context_start = max(0, pos - window)\n",
    "        context_end = min(len(text), pos + len(entity) + window)\n",
    "        context = text[context_start:context_end]\n",
    "        \n",
    "        # Analyze sentiment\n",
    "        sentiment = sia.polarity_scores(context)['compound']\n",
    "        results.append((context, sentiment))\n",
    "        \n",
    "        start = pos + 1\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment around mentions of key figures\n",
    "all_text = ' '.join(corpus['text'])\n",
    "\n",
    "entities_to_check = ['Grigsu', 'Yasho', 'stone-school', 'water-school', 'dissolution']\n",
    "\n",
    "for entity in entities_to_check:\n",
    "    mentions = sentiment_around_entity(all_text, entity)\n",
    "    if mentions:\n",
    "        avg_sentiment = np.mean([s for _, s in mentions])\n",
    "        print(f\"\\n'{entity}': {len(mentions)} mentions, average sentiment: {avg_sentiment:.3f}\")\n",
    "        \n",
    "        # Show most positive and negative mentions\n",
    "        sorted_mentions = sorted(mentions, key=lambda x: x[1])\n",
    "        if sorted_mentions:\n",
    "            print(f\"  Most negative: {sorted_mentions[0][1]:.3f}\")\n",
    "            print(f\"  Most positive: {sorted_mentions[-1][1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Sentiment and Authenticity\n",
    "\n",
    "Do suspected forgeries have different sentiment patterns than authentic documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add authenticity status to sentiment data\n",
    "sentiment_df = sentiment_df.merge(\n",
    "    manuscripts[['manuscript_id', 'authenticity_status']],\n",
    "    on='manuscript_id', how='left'\n",
    ")\n",
    "\n",
    "# Compare authentic vs suspected\n",
    "auth_comparison = sentiment_df.groupby('authenticity_status').agg({\n",
    "    'compound': 'mean',\n",
    "    'positive': 'mean',\n",
    "    'negative': 'mean',\n",
    "    'std_sentence_sentiment': 'mean',\n",
    "    'manuscript_id': 'count'\n",
    "}).rename(columns={'manuscript_id': 'count'}).round(3)\n",
    "\n",
    "print(\"Sentiment by authenticity status:\")\n",
    "print(auth_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Sentiment analysis basics**: Positive, negative, neutral, compound scores\n",
    "2. **VADER**: A rule-based sentiment analyzer\n",
    "3. **Document-level analysis**: Overall and sentence-level sentiment\n",
    "4. **Entity-level analysis**: Sentiment around specific mentions\n",
    "5. **Comparative analysis**: Sentiment by author, genre, authenticity\n",
    "\n",
    "### Insights from the Archive\n",
    "\n",
    "Sentiment analysis reveals:\n",
    "- Which genres tend to be more emotionally charged\n",
    "- How different scholars are discussed\n",
    "- Whether disputed documents have unusual sentiment patterns\n",
    "\n",
    "---\n",
    "\n",
    "*The marginal annotations reveal much: readers who praised and readers who condemned, opinions that shifted over time, reputations that rose and fell. The ink has faded, but the sentiments persist.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 8.1: Custom Sentiment Lexicon\n",
    "VADER is general-purpose. Create a custom lexicon for the archive's philosophical vocabulary (e.g., \"dissolution\" might be positive for water-school, negative for stone-school)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8.2: Sentiment Trajectory\n",
    "For longer documents, plot how sentiment changes from beginning to end. Do arguments build to a climax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}